<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <title>interview 1 (1)LLM简单介绍（2）LLM中“B”的意思</title>
    <link rel="stylesheet" href="../style.css" />
</head>
<body>
    <h1>interview 1 (1)LLM简单介绍（2）LLM中“B”的意思</h1>
    <p><strong>（1）LLM简单介绍：</strong>大模型：一般指1亿以上参数的模型，但目前万亿参数级别也已出现（如 Minmax abab6.5）。</p>

    <p>大语言模型（LLMs）是专注于语言处理的大模型。</p>

    <p><strong>主要特点：</strong></p>
    <p>1、大规模参数：如 GPT-3 有 175B，PaLM 有 540B，增强理解能力。</p>
    <p>2、多任务能力：能执行文本摘要、情感分析、翻译等多任务。</p>
    <p>3、上下文理解强：生成内容连贯、有逻辑。</p>
    <p>4、自监督训练：无需标注数据，通过预测来学习语言结构。</p>
    <p>5、通用性强：支持跨任务、跨领域的迁移。</p>

    <p>⚠️ 但 LLM 也有局限，比如信息虚构、解释能力差、资源消耗高等。</p>
    <p><strong>（2）LLM中“B”的意思：</strong>在大语言模型(LLMs)名称后面跟随的数字如“175B”指的是模型的参政数量(parameters)，通常以“B”表示billion"，即“十亿”。</p>



    <p><strong>这些参数数量直接影响模型的复杂性和计算能力：</strong></p>


    <p>⚠️ 参数数量越多，模型能学习和捕捉的语言模式和语义信息也越丰富，但对计算资源的要求也随之增加。不过增加参数数量并不直接等于更好效果。</p>



    <pre><code class="language-python">

  </code></pre>

    <p><a href="../index.html">⬅ 返回首页</a></p>
</body>
</html>

